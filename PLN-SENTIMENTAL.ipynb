{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 4s 47ms/step - loss: 1.6139 - accuracy: 0.1963 - val_loss: 1.6076 - val_accuracy: 0.2100\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 1.6160 - accuracy: 0.1825 - val_loss: 1.6067 - val_accuracy: 0.2350\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 1.5396 - accuracy: 0.2663 - val_loss: 1.3394 - val_accuracy: 0.3750\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 1.3064 - accuracy: 0.3613 - val_loss: 1.2368 - val_accuracy: 0.4050\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 1.1366 - accuracy: 0.4387 - val_loss: 1.2361 - val_accuracy: 0.4650\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.9515 - accuracy: 0.5725 - val_loss: 1.1830 - val_accuracy: 0.4400\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 0.9104 - accuracy: 0.5900 - val_loss: 1.0257 - val_accuracy: 0.6900\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 3s 50ms/step - loss: 0.6955 - accuracy: 0.7362 - val_loss: 1.0874 - val_accuracy: 0.6400\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.4858 - accuracy: 0.8275 - val_loss: 0.9874 - val_accuracy: 0.7150\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.5930 - accuracy: 0.7775 - val_loss: 1.1183 - val_accuracy: 0.6700\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.1906 - accuracy: 0.6840\n",
      "Test Score: 1.1905533075332642\n",
      "Test Accuracy: 0.6840000152587891\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "# Carrega o léxico em um DataFrame\n",
    "lexico = pd.read_csv('lexico_czar.csv')\n",
    "\n",
    "# Remove stopwords e pontuações\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "lexico['text'] = lexico['text'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
    "lexico['text'] = lexico['text'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]', '', x))\n",
    "\n",
    "# Mapeia as emoções do léxico para os rótulos utilizados no modelo\n",
    "emotions_mapping = {'Felicidade': 'happy', 'Tristeza': 'sad', 'Raiva': 'angry', 'Neutralidade': 'neutral', 'Dúvida': 'doubt'}\n",
    "lexico['emotion'] = lexico['emotion'].map(emotions_mapping)\n",
    "\n",
    "# Define os dados de entrada e saída\n",
    "X = lexico['text'].values\n",
    "Y = pd.get_dummies(lexico['emotion']).values\n",
    "\n",
    "# Divide os dados em conjunto de treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)\n",
    "\n",
    "# Define o tokenizer e o tamanho máximo das sequências\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=True)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "max_length = len(max(X_train, key=len).split())\n",
    "\n",
    "# Transforma os textos em sequências de tokens e preenche as sequências com zeros (padding)\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=max_length, padding='post')\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_length, padding='post')\n",
    "\n",
    "# Define o modelo da rede neural\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 128, input_length=max_length))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.4))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Treina o modelo com o conjunto de treino e valida com o conjunto de teste\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)\n",
    "history = model.fit(X_train, Y_train, epochs=10, batch_size=16, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Avalia o modelo com o conjunto de teste\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "model.save('pln_analise.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 521ms/step\n",
      "emoções das frases:  ['Felicidade', 'Felicidade', 'Tristeza', 'Tristeza', 'Felicidade']\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Carrega o modelo\n",
    "model = load_model('pln_analise.h5')\n",
    "\n",
    "# Define os dados de entrada\n",
    "new_text = ['Eu te odeio', 'ta dando bom', 'expectativa', 'Meu cachorro morreu', 'Como posso ajudar?']\n",
    "\n",
    "# Transforma o texto em uma sequência de tokens e preenche com zeros\n",
    "new_seq = pad_sequences(tokenizer.texts_to_sequences(new_text), maxlen=max_length, padding='post')\n",
    "\n",
    "# Faz a previsão de emoção do texto usando o modelo carregado\n",
    "prediction = model.predict(new_seq)\n",
    "\n",
    "# Obtém a classe prevista para cada exemplo de teste\n",
    "predicted_classes = prediction.argmax(axis=-1)\n",
    "\n",
    "# Obtém os nomes das emoções correspondentes às classes previstas\n",
    "emotions = ['Raiva', 'Felicidade', 'Neutralidade', 'Tristeza', 'Dúvida']\n",
    "predicted_emotions = [emotions[pred_class] for pred_class in predicted_classes]\n",
    "\n",
    "# Imprime a previsão\n",
    "print(f'emoções das frases: ', predicted_emotions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
