{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino do modelo do zero\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "# Carrega o léxico em um DataFrame\n",
    "lexico = pd.read_csv('datasets/lexico_czar_train.csv')\n",
    "\n",
    "# Remove stopwords e pontuações\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "lexico['text'] = lexico['text'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
    "lexico['text'] = lexico['text'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]', '', x))\n",
    "\n",
    "# Mapeia as emoções do léxico para os rótulos utilizados no modelo\n",
    "emotions_mapping = {'Felicidade': 'happy', 'Tristeza': 'sad', 'Raiva': 'angry', 'Neutralidade': 'neutral', 'Dúvida': 'doubt'}\n",
    "lexico['emotion'] = lexico['emotion'].map(emotions_mapping)\n",
    "\n",
    "# Define os dados de entrada e saída\n",
    "X = lexico['text'].values\n",
    "Y = pd.get_dummies(lexico['emotion']).values\n",
    "\n",
    "# Divide os dados em conjunto de treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)\n",
    "\n",
    "# Define o tokenizer e o tamanho máximo das sequências\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=True)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "max_length = len(max(X_train, key=len).split())\n",
    "\n",
    "# Transforma os textos em sequências de tokens e preenche as sequências com zeros (padding)\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=max_length, padding='post')\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_length, padding='post')\n",
    "\n",
    "# Define o modelo da rede neural\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 128, input_length=max_length))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.4))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Treina o modelo com o conjunto de treino e valida com o conjunto de teste\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=1000, min_delta=0.0001)\n",
    "history = model.fit(X_train, Y_train, epochs=500, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Avalia o modelo com o conjunto de teste\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "model.save('pln_analise.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 208ms/step\n",
      "emoções das frases:  ['Raiva', 'Felicidade', 'Neutralidade', 'Raiva', 'Dúvida']\n"
     ]
    }
   ],
   "source": [
    "#TESTE DE MODELO\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "# Carrega o modelo\n",
    "model = load_model('./training_Networks/pln_analise_75%.h5')\n",
    "\n",
    "# Define os dados de entrada\n",
    "new_text = ['Eu te odeio', 'ta dando bom', 'faz tanto sol', 'Ai que raiva', 'você está triste hoje?']\n",
    "\n",
    "# Transforma o texto em uma sequência de tokens e preenche com zeros\n",
    "new_seq = pad_sequences(tokenizer.texts_to_sequences(new_text), maxlen=max_length, padding='post')\n",
    "\n",
    "# Faz a previsão de emoção do texto usando o model carregado\n",
    "prediction = model.predict(new_seq)\n",
    "\n",
    "# Obtém a classe prevista para cada exemplo de teste\n",
    "predicted_classes = prediction.argmax(axis=-1)\n",
    "\n",
    "# Obtém os nomes das emoções correspondentes às classes previstas\n",
    "emotions = ['Raiva', 'Felicidade', 'Neutralidade', 'Tristeza', 'Dúvida']\n",
    "predicted_emotions = [emotions[pred_class] for pred_class in predicted_classes]\n",
    "\n",
    "# Imprime a previsão\n",
    "print(f'emoções das frases: ', predicted_emotions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
