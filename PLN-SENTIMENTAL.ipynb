{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 3s 61ms/step - loss: 1.5151 - accuracy: 0.4555 - val_loss: 1.3435 - val_accuracy: 0.5070\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.3179 - accuracy: 0.5089 - val_loss: 1.2143 - val_accuracy: 0.5070\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.2316 - accuracy: 0.5089 - val_loss: 1.1511 - val_accuracy: 0.5070\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.0637 - accuracy: 0.5338 - val_loss: 0.9023 - val_accuracy: 0.6197\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.8211 - accuracy: 0.6406 - val_loss: 0.7639 - val_accuracy: 0.6761\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.7536 - accuracy: 0.6904 - val_loss: 0.7451 - val_accuracy: 0.7324\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.7123 - accuracy: 0.6904 - val_loss: 0.7576 - val_accuracy: 0.7324\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6770 - accuracy: 0.7046 - val_loss: 0.7517 - val_accuracy: 0.7183\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.6459 - accuracy: 0.7046 - val_loss: 0.6898 - val_accuracy: 0.7465\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5967 - accuracy: 0.7153 - val_loss: 0.6476 - val_accuracy: 0.7465\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6697 - accuracy: 0.7500\n",
      "Test Score: 0.6697301864624023\n",
      "Test Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "# Carrega o léxico em um DataFrame\n",
    "lexico = pd.read_csv('lexico_czar.csv')\n",
    "\n",
    "# Remove stopwords e pontuações\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "lexico['text'] = lexico['text'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
    "lexico['text'] = lexico['text'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]', '', x))\n",
    "\n",
    "# Mapeia as emoções do léxico para os rótulos utilizados no modelo\n",
    "emotions_mapping = {'Felicidade': 'happy', 'Tristeza': 'sad', 'Raiva': 'angry', 'Neutralidade': 'neutral', 'Sarcasmo': 'sarcasm'}\n",
    "lexico['emotion'] = lexico['emotion'].map(emotions_mapping)\n",
    "\n",
    "# Define os dados de entrada e saída\n",
    "X = lexico['text'].values\n",
    "Y = pd.get_dummies(lexico['emotion']).values\n",
    "\n",
    "# Divide os dados em conjunto de treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)\n",
    "\n",
    "# Define o tokenizer e o tamanho máximo das sequências\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=True)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "max_length = len(max(X_train, key=len).split())\n",
    "\n",
    "# Transforma os textos em sequências de tokens e preenche as sequências com zeros (padding)\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=max_length, padding='post')\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_length, padding='post')\n",
    "\n",
    "# Define o modelo da rede neural\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 128, input_length=max_length))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.4))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Treina o modelo com o conjunto de treino e valida com o conjunto de teste\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)\n",
    "history = model.fit(X_train, Y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Avalia o modelo com o conjunto de teste\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "model.save('pln_analise.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 180ms/step\n",
      "['Tristeza']\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Carrega o modelo\n",
    "model = load_model('pln_analise.h5')\n",
    "\n",
    "# Define os dados de entrada\n",
    "new_text = ['Meu cachorro morreu']\n",
    "\n",
    "# Transforma o texto em uma sequência de tokens e preenche com zeros\n",
    "new_seq = pad_sequences(tokenizer.texts_to_sequences(new_text), maxlen=max_length, padding='post')\n",
    "\n",
    "# Faz a previsão de emoção do texto usando o modelo carregado\n",
    "prediction = model.predict(new_seq)\n",
    "\n",
    "# Obtém a classe prevista para cada exemplo de teste\n",
    "predicted_classes = prediction.argmax(axis=-1)\n",
    "\n",
    "# Obtém os nomes das emoções correspondentes às classes previstas\n",
    "emotions = ['Raiva', 'Felicidade', 'Neutralidade', 'Tristeza', 'Sarcasmo']\n",
    "predicted_emotions = [emotions[pred_class] for pred_class in predicted_classes]\n",
    "\n",
    "# Imprime a previsão\n",
    "print(predicted_emotions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
